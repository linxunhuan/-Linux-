# 页面错误基础
## 页面错误基础知识
+ 今天的课程内容是page fault，以及通过page fault可以实现的一系列虚拟内存功能
  + 这里相关的功能有：
    + lazy allocation       —— 讲过的
    + copy-on-write fork    —— 写时复制分叉
    + demand paging         —— 请求调页
    + memory mapped files   —— 内存映射文件
+ 然而在XV6中，上述功能都没实现
+ 在XV6中，一旦用户空间进程触发了page fault，会导致进程被杀掉
+ 在进入到具体细节之前，我们先来简单回顾一下虚拟内存
  + 虚拟内存有两个主要的优点：
    + 第一个是Isolation，隔离性
      + 虚拟内存使得操作系统可以为每个应用程序提供属于它们自己的地址空间
        + 所以一个应用程序不可能有意或者无意的修改另一个应用程序的内存数据
      + 虚拟内存同时也提供了用户空间和内核空间的隔离性
    + 另一个好处是level of indirection，提供了一层抽象
      + 处理器和所有的指令都可以使用虚拟地址，而内核会定义从虚拟地址到物理地址的映射关系
        + 这一层抽象是我们这节课要讨论的许多有趣功能的基础
      + 不过到目前为止，在XV6中内存地址的映射都比较无聊，实际上在内核中基本上是直接映射（注，也就是虚拟地址等于物理地址）
      + 当然也有几个比较有意思的地方：
        + trampoline page —— 它使得内核可以将一个物理内存page映射到多个用户地址空间中
        + guard page      —— 它同时在内核空间和用户空间用来保护Stack
+ 到目前为止，我们介绍的内存地址映射相对来说比较静态
  + 不管是user page table还是kernel page table，都是在最开始的时候设置好，之后就不会再做任何变动
---------------------------
+ page fault可以让这里的地址映射关系变得动态起来
+ 通过page fault，内核可以更新page table
  + 因为现在可以动态的更新虚拟地址这一层抽象，结合page table和page fault，内核将会有巨大的灵活性
  + 我们接下来会看到各种各样利用动态变更page table实现的有趣的功能
+ 但是在那之前，首先，我们需要思考的是，什么样的信息对于page fault是必须的
  + 或者说，当发生page fault时，内核需要什么样的信息才能够响应page fault
+ 很明显的，我们需要出错的虚拟地址，或者是触发page fault的源，所以要获取以下三个信息
  + 第一个信息：当出现page fault的时候，XV6内核会打印出错的虚拟地址，并且这个地址会被保存在STVAL寄存器中
    + 所以，当一个程序触发了page fault
    + page fault会使用trap机制，将程序运行切换到内核，同时也会将出错的地址存放在STVAL寄存器中
  + 第二个信息：对不同场景的page fault有不同的响应
      + 比如因为load指令触发的page fault
      + 因为store指令触发的page fault
      + 因为jump指令触发的page fault
    + 所以RISC-V的文档，在SCAUSE（注，Supervisor cause寄存器，保存了trap机制中进入到supervisor mode的原因）寄存器的介绍中，有多个与page fault相关的原因
      + 比如，13表示是因为load引起的page fault
      + 15表示是因为store引起的page fault
      + 12表示是因为指令执行引起的page fault
    + 所以该信息存在SCAUSE寄存器中，其中总共有3个类型的原因与page fault相关，分别是读、写和指令
    + ECALL进入到supervisor mode对应的是8，这是我们在上节课中应该看到的SCAUSE值
  + 第三个信息：触发page fault的指令的地址
    + 这个地址存放在SEPC（Supervisor Exception Program Counter）寄存器中，并同时会保存在trapframe->epc中
总结上面的内容，就是：
```
当出现了page fault，现在有了3个对我们来说极其有价值的信息，分别是：
1、引起page fault的内存地址
2、引起page fault的原因类型
3、引起page fault时的程序计数器值，这表明了page fault在用户空间发生的位置
```
## 惰性页面分配
+ sbrk是XV6提供的系统调用，它使得用户应用程序能扩大自己的heap
+ 当一个应用程序启动的时候，sbrk指向的是heap的最底端，同时也是stack的最顶端
  + 这个位置通过代表进程的数据结构中的sz字段表示，这里以_p->sz表示
+ 当调用sbrk时
  + 它的参数是整数，代表了你想要申请的page数量
  + sbrk会扩展heap的上边界（也就是会扩大heap）
    + 这意味着，当sbrk实际发生或者被调用的时候
      + 内核会分配一些物理内存
      + 并将这些内存映射到用户应用程序的地址空间
      + 然后将内存内容初始化为0
      + 再返回sbrk系统调用
    + 这样，应用程序可以通过多次sbrk系统调用来增加它所需要的内存
+ 类似的，应用程序还可以通过给sbrk传入负数作为参数，来减少或者压缩它的地址空间
+ 在XV6中，sbrk的实现默认是eager allocation
  + 这表示了，一旦调用了sbrk，内核会立即分配应用程序所需要的物理内存
  + 但是实际上，对于应用程序来说很难预测自己需要多少内存
    + 所以通常来说，应用程序倾向于申请多于自己所需要的内存
  + 这意味着，进程的内存消耗会增加许多，但是有部分内存永远也不会被应用程序所使用到
+ 当我们看到了一个page fault，相应的虚拟地址小于当前_p->sz_，同时大于stack
  + 那么我们就知道这是一个来自于heap的地址，但是内核还没有分配任何物理内存
  + 所以对于这个page fault的响应也理所当然的直接明了：
    + 在page fault handler中，通过kalloc函数分配一个内存page
    + 初始化这个page内容为0
    + 将这个内存page映射到user page table中
    + 最后重新执行指令
      + 比方说，如果是load指令，或者store指令要访问属于当前进程但是还未被分配的内存，在我们映射完新申请的物理内存page之后，重新执行指令应该就能通过了
--------------------------------------------
### lazy allocation相关代码
```c
uint64
sys_sbrk(void){
    int addr;
    int n;
    if(argint(0，&n)< 0)
        return -l;
    addr = myproc()->sz;
    if(growproc(n)< 0)
        return -l;
    return addr;
}
```
+ 这里我们要修改这个函数，让它只对p->sz加n，并不执行增加内存的操作
```c
uint64
sys_sbrk(void){
    int addr;
    int n;
    
    if(argint(0，&n)< 0)
        return -1;
    addr = myproc()->sz;
    myproc()->sz= myproc()->sz + n;
    // if(growproc(n)< 0)
    // return -1;
    return addr;
}
```
修改完之后启动XV6，并且执行“echo hi”，我们会得到一个page fault
<img src=".\picture\image84.png">   

+ 之所以会得到一个page fault是因为:
  + 在Shell中执行程序，Shell会先fork一个子进程
  + 子进程会通过exec执行echo
  + 在这个过程中，Shell会申请一些内存，所以Shell会调用sys_sbrk，然后就出错了（注，因为前面修改了代码，调用sys_sbrk不会实际分配所需要的内存）
+ 这里输出的内容包含了一些有趣的信息：
  + 这里输出了SCAUSE寄存器内容，我们可以看到它的值是15，表明这是一个store page fault（详见8.1）
  + 我们可以看到进程的pid是3，这极可能是Shell的pid
  + 我们还可以看到SEPC寄存器的值，是0x12a4
  + 最后还可以看到出错的虚拟内存地址，也就是STVAL寄存器的内容，是0x4008
+ 我们可以查看Shell的汇编代码，这是由Makefile创建的
    + 我们搜索SEPC对应的地址，可以看到这的确是一个store指令
    + 这看起来就是我们出现page fault的位置
<img src=".\picture\image85.png">  

+ 如果我们向前看看汇编代码，我们可以看到page fault是出现在malloc的实现代码中
  + 在malloc的实现中，我们使用sbrk系统调用来获得一些内存
  + 之后会初始化我们刚刚获取到的内存
  + 在0x12a4位置，刚刚获取的内存中写入数据
  + 但是实际上我们在向未被分配的内存写入数据
+ 另一个可以证明内存还没有分配的地方是，XV6中Shell通常是有4个page，包含了text和data
+ 出错的地址在4个page之外，也就是第5个page，实际上我们在4个page之外8个字节
  + 这也合理，因为在0x12a4对应的指令中，a0持有的是0x4000，而8相对a0的偏移量
  + 偏移之后的地址就是我们想要使用的地址（注，也就是出错的地址）
+ 以上就是page fault的信息。我们接下来看看如何能够聪明的处理这里的page fault
  + 首先查看trap.c中的usertrap函数
    + 在usertrap中根据不同的SCAUSE完成不同的操作
<img src=".\picture\image86.png">  

+ 在上面增加的代码中，首先打印一些调试信息
+ 之后分配一个物理内存page
  + 如果ka等于0，表明没有物理内存我们现在OOM了，我们会杀掉进程
+ 如果有物理内存
  + 首先会将内存内容设置为0
  + 之后将物理内存page指向用户地址空间中合适的虚拟内存地址
  + 具体来说，我们首先将虚拟地址向下取整，这里引起page fault的虚拟地址是0x4008，向下取整之后是0x4000
    + 之后我们将物理内存地址跟取整之后的虚拟内存地址的关系加到page table中
    + 对应的PTE需要设置常用的权限标志位，在这里是u，w，r bit位
  + 接下来运行一些这部分代码
    + 先重新编译XV6
    + 再执行“echo hi”
<img src=".\picture\image87.png"> 

+ 但是实际上并没有正常工作
+ 我们这里有两个page fault
  + 第一个对应的虚拟内存地址是0x4008
  + 在处理这个page fault时，我们又有了另一个page fault 0x13f48
+ 现在唯一的问题是，uvmunmap在报错，一些它尝试unmap的page并不存在
  + 这里unmap的是之前lazy allocated，但是又还没有用到的地址
  + 所以对于这个内存，并没有对应的物理内存
  + 所以在uvmunmap函数中，当PTE的v标志位为0并且没有对应的mapping，这并不是一个实际的panic，这是我们预期的行为
<img src=".\picture\image88.png"> 
实际上，对于这个page我们并不用做任何事情，我们可以直接continue跳到下一个page
<img src=".\picture\image89.png"> 

+ 接下来，我们再重新编译XV6，并执行“echo hi”
<img src=".\picture\image90.png"> 

+ 现在我们可以看到2个page fault，但是echo hi正常工作了
+ 现在，我们一定程度上有了最基本最简单的lazy allocation
## 按需填零
+ 另一个简单但是使用的非常频繁的功能是zero-fill-on-demand
+ 当查看一个用户程序的地址空间时
  + 存在text区域
  + data区域
  + BSS区域（注，BSS区域包含了未被初始化或者初始化为0的全局或者静态变量）
+ 当编译器在生成二进制文件时，编译器会填入这三个区域
  + text区域是程序的指令
  + data区域存放的是初始化了的全局变量
  + BSS包含了未被初始化或者初始化为0的全局变量
+ 之所以这些变量要单独列出来，是因为例如你在C语言中定义了一个大的矩阵作为全局变量
  + 它的元素初始值都是0
  + 为什么要为这个矩阵分配内存呢？其实只需要记住这个矩阵的内容是0就行
+ 在一个正常的操作系统中，如果执行exec，exec会申请地址空间，里面会存放text和data
+ 因为BSS里面保存了未被初始化的全局变量，这里或许有许多许多个page，但是所有的page内容都为0
+ 通常可以调优的地方是，我有如此多的内容全是0的page
  + 在物理内存中，我只需要分配一个page，这个page的内容全是0
  + 然后将所有虚拟地址空间的全0的page都map到这一个物理page上
  + 这样至少在程序启动的时候能节省大量的物理内存分配
+ 我们不能允许对于这个page执行写操作
  + 因为所有的虚拟地址空间page都期望page的内容是全0
  + **所以这里的PTE都是只读的**
+ 之后在某个时间点，应用程序尝试写BSS中的一个page时
  + 比如说需要更改一两个变量的值,我们会得到page fault
  + 假设store指令发生在BSS最顶端的page中,我们要做的是:
    + 物理内存中申请一个新的内存page
    + 将其内容设置为0
      + 因为我们预期这个内存的内容为0
    + 之后我们需要更新这个page的mapping关系
      + 首先PTE要设置成可读可写
      + 然后将其指向新的物理page
        + 这里相当于更新了PTE，之后我们可以重新执行指令
+ 这么做的优点：
  + 优点一：
    + 这里类似于lazy allocation
    + 假设程序申请了一个大的数组，来保存可能的最大的输入，并且这个数组是全局变量且初始为0
    + 但是最后或许只有一小部分内容会被使用
  + 优点二：
    + 在exec中需要做的工作变少了
    + 程序可以启动的更快，这样你可以获得更好的交互体验
      + 因为你只需要分配一个内容全是0的物理page
      + 所有的虚拟page都可以映射到这一个物理page上
## 写时复制分叉
+ copy-on-write fork，有时也称为COW fork
+ 当Shell处理指令时，它会通过fork创建一个子进程
  + fork会创建一个Shell进程的拷贝
  + 所以这时我们有一个父进程（原来的Shell）和一个子进程
+ Shell的子进程执行的第一件事情就是调用exec运行一些其他程序
    + 比如运行echo
  + 现在的情况是，fork创建了Shell地址空间的一个完整的拷贝
  + 而exec做的第一件事情就是丢弃这个地址空间
  + 取而代之的是一个包含了echo的地址空间
    + 这里看起来有点浪费
+ 所以对于这个特定场景有一个非常有效的优化：
  + 当我们创建子进程时，与其创建，分配并拷贝内容到新的物理内存
  + 其实我们可以直接共享父进程的物理内存page
  + 所以这里，我们可以设置子进程的PTE指向父进程对应的物理内存page
+ 但是，一旦子进程想要修改这些内存的内容，相应的更新应该对父进程不可见
  + 因为我们希望在父进程和子进程之间有强隔离性
  + 为了确保进程间的隔离性，**父进程和子进程的PTE的标志位都设置成只读的**
+ 当我们需要更改内存的内容时，我们会得到page fault
  + 因为父进程和子进程都会继续运行
  + 而父进程或者子进程都可能会执行store指令来更新一些全局变量，这时就会触发page fault
    + 因为现在在向一个只读的PTE写数据
+ 在得到page fault之后，我们需要拷贝相应的物理page
  + 假设现在是子进程在执行store指令
    + 那么我们会分配一个新的物理内存page
    + 然后将page fault相关的物理内存page拷贝到新分配的物理内存page中
    + 并将新分配的物理内存page映射到子进程
  + 这时，新分配的物理内存page只对子进程的地址空间可见
    + 所以我们可以将相应的PTE设置成可读写，并且我们可以重新执行store指令
  + 实际上，对于触发刚刚page fault的物理page
    + 因为现在只对父进程可见，相应的PTE对于父进程也变成可读写的了
+ 所以现在，我们拷贝了一个page
  + 将新的page映射到相应的用户地址空间
  + 并重新执行用户指令
    + 重新执行用户指令是指调用userret函数，也即是lec06中介绍的返回到用户空间的方法
+ 目前在XV6中，**除了trampoline page外，一个物理内存page只属于一个用户进程**
  + trampoline page永远也不会释放，所以也不是什么大问题
  + 但是对于这里的物理内存page，现在有多个用户进程或者说多个地址空间都指向了相同的物理内存page
    + 举个例子，当父进程退出时我们需要更加的小心
    + 因为我们要判断是否能立即释放相应的物理page
    + 如果有子进程还在使用这些物理page，而内核又释放了这些物理page
    + 那么现在释放内存page的依据是什么呢？
+ 我们需要对于每一个物理内存page的引用进行计数
  + 当我们释放虚拟page时，我们将物理内存page的引用数减1
  + 如果引用数等于0，那么我们就能释放物理内存page
  + 所以在copy-on-write lab中，你们需要引入一些额外的数据结构或者元数据信息来完成引用计数
## 请求调页
+ Demand paging
+ 在未修改的XV6中，操作系统会加载程序内存的text，data区域
  + 并且以eager的方式将这些区域加载进page table
+ 但是根据我们在lazy allocation和zero-filled on demand的经验
  + 为什么我们要以eager的方式将程序加载到内存中
  + 为什么不再等等，直到应用程序实际需要这些指令的时候再加载内存
    + 程序的二进制文件可能非常的巨大，将它全部从磁盘加载到内存中将会是一个代价很高的操作
    + 又或者data区域的大小远大于常见的场景所需要的大小，我们并不一定需要将整个二进制都加载到内存中
+ 所以对于exec，在虚拟地址空间中，我们为text和data分配好地址段
+ 但是相应的PTE并不对应任何物理内存page
  + 对于这些PTE，我们只需要将valid bit位设置为0即可
+ 如果我们修改XV6使其按照上面的方式工作，我们什么时候会得到第一个page fault呢
+ 用户应用程序运行的第一条指令是什么？
+ 用户应用程序在哪里启动的？
+ 应用程序是从地址0开始运行
  + text区域从地址0开始向上增长
  + 位于地址0的指令是会触发第一个page fault的指令
    + 因为我们还没有真正的加载内存
+ 那么该如何处理这里的page fault呢？
  + 首先我们可以发现，这些page是on-demand page
  + 我们需要在某个地方记录了这些page对应的程序文件
    + 我们在page fault handler中需要从程序文件中读取page数据,加载到内存中
    + 之后将内存page映射到page table
    + 最后再重新执行指令
+ 在最坏的情况下，用户程序使用了text和data中的所有内容，那么我们将会在应用程序的每个page都收到一个page fault
+ 但是如果我们幸运的话，用户程序并没有使用所有的text区域或者data区域
  + 那么我们一方面可以节省一些物理内存
  + 另一方面我们可以让exec运行的更快（注，因为不需要为整个程序分配内存）
+ 前面描述的流程其实是有点问题的
  + 我们将要读取的文件，它的text和data区域可能大于物理内存的容量
  + 又或者多个应用程序按照demand paging的方式启动，它们二进制文件的和大于实际物理内存的容量
+ 对于demand paging来说，假设内存已经耗尽了或者说OOM了
  + 这个时候如果得到了一个page fault
  + 需要从文件系统拷贝中拷贝一些内容到内存中
  + 但这时你又没有任何可用的物理内存page
  + 这其实回到了之前的一个问题：在lazy allocation中，如果内存耗尽了该如何办？
+ 如果内存耗尽了，一个选择是撤回page（evict page）
  + 比如说将部分内存page中的内容写回到文件系统再撤回page
  + 一旦你撤回并释放了page，那么你就有了一个新的空闲的page
  + 可以使用这个刚刚空闲出来的page，分配给刚刚的page fault handler，再重新执行指令
+ 什么样的page可以被撤回？并且该使用什么样的策略来撤回page？
  + Least Recently Used，或者叫LRU
  + 除了这个策略之外，还有一些其他的小优化
+ 如果要撤回一个page，你需要在dirty page和non-dirty page中做选择
  + dirty page是曾经被写过的page
    + 如果dirty page之后再被修改，现在你或许需要对它写两次了（注，一次内存，一次文件）
  + non-dirty page是只被读过，但是没有被写过的page
    + 可以将内存page中的内容写到文件中
    + 之后将相应的PTE标记为non-valid，这就完成了所有的工作
    + 之后你可以在另一个page table重复使用这个page
    + 所以通常来说这里优先会选择non-dirty page来撤回
## 内存映射文件
+ 这节课最后要讨论的内容，也是后面的一个实验，就是memory mapped files
+ 这里的核心思想是:
  + **将完整或者部分文件加载到内存中，这样就可以通过内存地址相关的load或者store指令来操纵文件**
  + 为了支持这个功能，一个现代的操作系统会提供一个叫做mmap的系统调用
  + 这个系统调用会接收
    + 一个虚拟内存地址（VA）
    + 长度（len）
    + protection
    + 一些标志位
    + 一个打开文件的文件描述符
    + 偏移量（offset）
+ 从文件描述符对应的文件的偏移量的位置开始，映射长度为len的内容到虚拟内存地址VA，同时我们需要加上一些保护，比如只读或者读写
+ 假设文件内容是读写并且内核实现mmap的方式是eager方式（不过大部分系统都不会这么做）
  + 内核会从文件的offset位置开始
  + 将数据拷贝到内存
  + 设置好PTE指向物理内存的位置
  + 之后应用程序就可以使用load或者store指令来修改内存中对应的文件内容
+ 当完成操作之后，会有一个对应的unmap系统调用
  + 参数是虚拟地址（VA），长度（len）                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
    + 表明应用程序已经完成了对文件的操作
  + 在unmap时间点，我们需要将dirty block写回到文件中
+ 我们可以很容易的找到哪些block是dirty的，因为它们在PTE中的dirty bit为1
+ 当然，在任何聪明的内存管理机制中，所有的这些都是以lazy的方式实现
  + 你不会立即将文件内容拷贝到内存中，而是先记录一下这个PTE属于这个文件描述符
  + 相应的信息通常在VMA结构体中保存，VMA全称是Virtual Memory Area
    + 例如对于这里的文件f，会有一个VMA，在VMA中我们会记录文件描述符，偏移量等等
    + 这些信息用来表示对应的内存虚拟地址的实际内容在哪，这样当我们得到一个位于VMA地址范围的page fault时，内核可以从磁盘中读数据，并加载到内存中
    + 所以这里回答之前一个问题
      + dirty bit是很重要的，因为在unmap中，你需要向文件回写dirty block。
 
--------------------------
+ 总结一下最近几节课的内容
  + 我们首先详细看了一下page table是如何工作的
  + 之后我们详细看了一下trap是如何工作的
  + 而page fault结合了这两部分的内容，可以用来实现非常强大且优雅的虚拟内存功能
+ 我们这节课介绍的内容，只是操作系统里面基于page fault功能的子集
  + 一个典型的操作系统实现了今天讨论的所有内容，如果你查看Linux，它包含了所有的内容，以及许多其他有趣的功能
  + 一旦你可以在page fault handler中动态的更新page table，虚拟内存将会变得有多强大

































